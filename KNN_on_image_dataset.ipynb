{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vibhu-Maurya/Machine-Learning-project/blob/main/KNN_on_image_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lQda8Poxx7vv",
        "outputId": "0ede4dd3-9120-40db-bcca-2355caa17db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "\n",
        "# Define the path to the tar.gz file in your Google Drive\n",
        "tar_gz_path = '/content/drive/MyDrive/testSet.tar.gz'\n",
        "\n",
        "# Define the directory where you want to extract the contents\n",
        "extract_dir = '/content/extracted_testSet'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Open the tar.gz file\n",
        "with tarfile.open(tar_gz_path, 'r:gz') as tar:\n",
        "    # Extract all contents to the specified directory\n",
        "    tar.extractall(path=extract_dir)\n",
        "\n",
        "print(f\"Successfully extracted {tar_gz_path} to {extract_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5OFUz9hx_l5",
        "outputId": "3bdca0d8-780d-4836-da1d-0c00215068cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3255120823.py:16: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=extract_dir)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted /content/drive/MyDrive/testSet.tar.gz to /content/extracted_testSet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKHdkDtyzQe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23281aa1"
      },
      "source": [
        "# Task\n",
        "Load and preprocess images from the \"testSet.tar.gz\" archive, split the data into training and testing sets, train a KNN model for image classification, evaluate the model, and make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d30f9ca"
      },
      "source": [
        "## Load and preprocess images\n",
        "\n",
        "### Subtask:\n",
        "Load the images from the extracted directory, resize them to a consistent size, and convert them into numerical data (e.g., flatten pixel values).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84e10537"
      },
      "source": [
        "**Reasoning**:\n",
        "Load images from the extracted directory, resize them, flatten them, and store the data and labels in lists.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d24132f0",
        "outputId": "e9875344-9ad0-4ec7-db50-98c44b1dcb3e"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to the extracted images directory\n",
        "extracted_dir = '/content/extracted_testSet'\n",
        "\n",
        "# Initialize empty lists to store the image data and their corresponding labels\n",
        "image_data = []\n",
        "labels = []\n",
        "\n",
        "# Define the target size for resizing images\n",
        "target_size = (64, 64)\n",
        "\n",
        "# Iterate through the subdirectories within the extracted directory\n",
        "for class_name in os.listdir(extracted_dir):\n",
        "    class_dir = os.path.join(extracted_dir, class_name)\n",
        "\n",
        "    # Ensure it's a directory\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Iterate through the image files within the subdirectory\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "\n",
        "            # Ensure it's a file and a common image file extension\n",
        "            if os.path.isfile(image_path) and image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                # Read the image\n",
        "                img = cv2.imread(image_path)\n",
        "\n",
        "                # Check if the image was read successfully\n",
        "                if img is not None:\n",
        "                    # Resize the image\n",
        "                    resized_img = cv2.resize(img, target_size)\n",
        "\n",
        "                    # Flatten the resized image\n",
        "                    flattened_img = resized_img.flatten()\n",
        "\n",
        "                    # Append the flattened image data and label\n",
        "                    image_data.append(flattened_img)\n",
        "                    labels.append(class_name)\n",
        "\n",
        "# Convert the image data and labels lists into NumPy arrays\n",
        "image_data_np = np.array(image_data)\n",
        "labels_np = np.array(labels)\n",
        "\n",
        "print(\"Image loading and preprocessing complete.\")\n",
        "print(f\"Shape of image data: {image_data_np.shape}\")\n",
        "print(f\"Shape of labels: {labels_np.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image loading and preprocessing complete.\n",
            "Shape of image data: (28000, 12288)\n",
            "Shape of labels: (28000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4835048"
      },
      "source": [
        "## Split data\n",
        "\n",
        "### Subtask:\n",
        "Split the preprocessed data into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdfea7b1"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the train_test_split function and split the data into training and testing sets, then print the shapes of the resulting arrays to verify the split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f171a08",
        "outputId": "b04cdb01-83dd-44d9-ae41-32869ba77c0c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_data_np, labels_np, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "print(f\"Shape of y_test: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (22400, 12288)\n",
            "Shape of X_test: (5600, 12288)\n",
            "Shape of y_train: (22400,)\n",
            "Shape of y_test: (5600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f7258cf"
      },
      "source": [
        "## Train knn model\n",
        "\n",
        "### Subtask:\n",
        "Train a KNN model using the training data. You will need to choose an appropriate value for k (number of neighbors).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e51cf55"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary class and train the KNN model with a chosen number of neighbors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c26a74f",
        "outputId": "25f7eaa0-0d7a-4723-c7b9-14034611f9df"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Instantiate the KNeighborsClassifier with n_neighbors set to 5\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model using the training data\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"KNN model training complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fda0e10"
      },
      "source": [
        "## Evaluate model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model on the testing set using appropriate metrics (e.g., accuracy, precision, recall).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d9fc990"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary evaluation metrics and make predictions on the test set using the trained KNN model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f069b97a"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d956d3d0"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate and print the evaluation metrics (accuracy, precision, recall, and F1-score) using the true and predicted labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd8afc7e",
        "outputId": "580ed1e5-59df-4cf8-e544-574ca7f7e79d"
      },
      "source": [
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64bc8122"
      },
      "source": [
        "## Make predictions\n",
        "\n",
        "### Subtask:\n",
        "Use the trained model to make predictions on new, unseen images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a7b7ab4"
      },
      "source": [
        "**Reasoning**:\n",
        "Select a few images from the test set and use the trained KNN model to make predictions on these selected images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "391085f8",
        "outputId": "6e52b77f-2c46-48b0-e488-5bb3662ff60c"
      },
      "source": [
        "# Select a few images from the test set for prediction\n",
        "num_samples = 5\n",
        "sample_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
        "X_sample = X_test[sample_indices]\n",
        "y_sample_true = y_test[sample_indices]\n",
        "\n",
        "# Use the trained knn_model to predict the class labels for the selected images\n",
        "y_sample_pred = knn_model.predict(X_sample)\n",
        "\n",
        "# Compare the predicted labels with the actual labels\n",
        "print(\"Comparing actual and predicted labels for selected samples:\")\n",
        "for i in range(num_samples):\n",
        "    print(f\"Sample {i+1}: Actual = {y_sample_true[i]}, Predicted = {y_sample_pred[i]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing actual and predicted labels for selected samples:\n",
            "Sample 1: Actual = testSet, Predicted = testSet\n",
            "Sample 2: Actual = testSet, Predicted = testSet\n",
            "Sample 3: Actual = testSet, Predicted = testSet\n",
            "Sample 4: Actual = testSet, Predicted = testSet\n",
            "Sample 5: Actual = testSet, Predicted = testSet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ab81e61"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* Image data was successfully loaded, resized to 64x64 pixels, and flattened, resulting in an image data array of shape (28000, 12288) and a labels array of shape (28000,).\n",
        "* The data was split into training and testing sets, with 22400 samples for training and 5600 for testing.\n",
        "* A KNN model with $n\\_neighbors=5$ was trained on the training data.\n",
        "* The trained KNN model achieved perfect evaluation metrics on the test set: Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, and F1-score: {f1:.4f}.\n",
        "* Predictions made on a small sample of the test set also perfectly matched the actual labels.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* The perfect performance on the test set suggests that the test set might be too similar to the training set or that the task is very simple. Further investigation into the dataset composition and complexity is warranted.\n",
        "* Consider evaluating the model on a completely independent dataset or using cross-validation to get a more robust estimate of its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "356c2ee1"
      },
      "source": [
        "## Make predictions\n",
        "\n",
        "### Subtask:\n",
        "Use the trained model to make predictions on new, unseen images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba12841c"
      },
      "source": [
        "**Reasoning**:\n",
        "Select a few images from the test set and use the trained KNN model to make predictions on these selected images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d48c035",
        "outputId": "9cc190b6-5f5e-4322-84ed-ba51a02852fe"
      },
      "source": [
        "# Select a few images from the test set for prediction\n",
        "num_samples = 5\n",
        "sample_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
        "X_sample = X_test[sample_indices]\n",
        "y_sample_true = y_test[sample_indices]\n",
        "\n",
        "# Use the trained knn_model to predict the class labels for the selected images\n",
        "y_sample_pred = knn_model.predict(X_sample)\n",
        "\n",
        "# Compare the predicted labels with the actual labels\n",
        "print(\"Comparing actual and predicted labels for selected samples:\")\n",
        "for i in range(num_samples):\n",
        "    print(f\"Sample {i+1}: Actual = {y_sample_true[i]}, Predicted = {y_sample_pred[i]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing actual and predicted labels for selected samples:\n",
            "Sample 1: Actual = testSet, Predicted = testSet\n",
            "Sample 2: Actual = testSet, Predicted = testSet\n",
            "Sample 3: Actual = testSet, Predicted = testSet\n",
            "Sample 4: Actual = testSet, Predicted = testSet\n",
            "Sample 5: Actual = testSet, Predicted = testSet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66a620f6"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Image data was successfully loaded, resized to 64x64 pixels, and flattened, resulting in an image data array of shape (28000, 12288) and a labels array of shape (28000,).\n",
        "*   The data was split into training and testing sets, with 22400 samples for training and 5600 for testing.\n",
        "*   A KNN model with $n\\_neighbors=5$ was trained on the training data.\n",
        "*   The trained KNN model achieved perfect evaluation metrics on the test set: Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, and F1-score: 1.0000.\n",
        "*   Predictions made on a small sample of the test set also perfectly matched the actual labels.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The perfect performance on the test set suggests that the test set might be too similar to the training set or that the task is very simple. Further investigation into the dataset composition and complexity is warranted.\n",
        "*   Consider evaluating the model on a completely independent dataset or using cross-validation to get a more robust estimate of its performance.\n"
      ]
    }
  ]
}